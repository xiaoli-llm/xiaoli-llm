# 🚀 大模型小白成长之路

### 🤖 大模型相关技术栈
- **大模型训练**
  - 混合精度训练
  - 分布式训练
    - Deepspeed  
    - Megatron-LM
    - FSDP
- **大模型结构**
  - transformer、deepseek、千问、llama
- **模型量化**
  - llama.cpp
- **大模型推理加速**
  - vLLM（无二次开发能力，快速部署可以考虑）
  - TensorRT-LLM
  - Imdeploy（国内GPU硬件或者部署多模态大模型可以使用）
  - sglang（对性能有要求或者团队二次开发能力强可以使用）
- **Flash attention**
- **大模型预训练**
- **强化学习**
  - PPO、DPO、RLHF、GRPO、GSPO、GAPO
  - TRL库
- **大模型部署**
  - ollama
- **大模型微调**
  - Llama Factory - llama3,Qwen系列大模型
  - LORA微调
  - HuggingFace代码微调
- **多模态大模型**
  - VIT
- **gradio**
- **RAG**
  - llama index
  - Graph RAG
- **Agent**
  - dify
- **向量数据库**
  - milvus
  - chromaDB
- **docker(learning)（胖虎）**
- **Transformer架构（zomi酱）**
  - token机制
    - BPE（Byte Pair Encoding）
  - attention变种
  - 长序列挑战
  - 大模型参数配置及比例
- **CUDA编程（learning）**
  - cublas
  - cutlass
- **triton**
- **自制大模型推理框架**
- **数据工程**
  - 数据清洗
    - 正则表达式
 ### 🎯 未来学习计划
 - **幻觉、安全、时效性等问题解决**
 - **多模态大模型视觉信息语义分割与编码（多模态后学）**
 - **视觉与语言的语义对齐，多模态任务联合训练（多模态后学）**
 - **Shell脚本的编写**
 - **langchain,llama index,langraph**
