# 🚀 大模型小白成长之路

### 🤖 大模型相关技术栈
- **LORA微调**
- **模型量化**
  - llama.cpp
- **Llama系列简要原理**
- **混合精度训练**
- **PPO**
- **大模型推理加速**
  - vLLM（无二次开发能力，快速部署可以考虑）
  - TensorRT-LLM
  - Imdeploy（国内GPU硬件或者部署多模态大模型可以使用）
  - sglang（对性能有要求或者团队二次开发能力强可以使用）
- **Flash attention**
- **大模型预训练**
- **大模型部署**
  - ollama
- **大模型微调**
  - Llama Factory - llama3,Qwen系列大模型
- **多模态大模型**
  - VIT
- **gradio**
- **RAG**
  - llama index
  - Graph RAG
- **Agent**
  - dify
- **deepseek系列**
- **向量数据库**
  - milvus
- **docker(learning)（胖虎）**
- **Transformer架构（zomi酱）**
  - 对主流大模型的原理和差异有深入的理解：GPT、chatGPT、T5、GLM、PaLM、LLaMA、qwen
  - token机制 √
    - BPE（Byte Pair Encoding）
  - embedding √
    - RoPE
  - attention
  - attention变种
  - 长序列挑战
  - 大模型参数配置及比例
### 📚 近期学习计划
- **CUDA编程（learning）**
  - cublas
  - cutlass
- **大模型分布式训练**
  - Deepspeed
  - Megatron-LM
- **量化**
- **稀疏化**
- **低秩训练**
- **算子融合**
- **并行优化**
- **多层级存储**
- **自制大模型推理框架**
- **数据工程（learning）（zomi酱）**
  - 数据清洗
    - 正则表达式
 ### 🎯 未来学习计划
 - **大模型预训练方法**
 - **高效微调**
 - **模型评估**
 - **知识增强与工具增强**
 - **幻觉、安全、时效性等问题解决**
 - **训练和推理加速**
 - **模型量化**
 - **端侧落地**
 - **多模态大模型视觉信息语义分割与编码（多模态后学）**
 - **视觉与语言的语义对齐，多模态任务联合训练（多模态后学）**
 - **强化学习**
 - **RL对齐RLHF**
 - **模型评估**
 - **Shell脚本的编写**
